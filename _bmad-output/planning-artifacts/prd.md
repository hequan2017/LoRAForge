---
stepsCompleted: ['step-01-init', 'step-02-discovery', 'step-03-success', 'step-04-journeys', 'step-05-domain', 'step-06-innovation', 'step-07-project-type', 'step-08-scoping', 'step-09-functional', 'step-10-nonfunctional', 'step-11-polish', 'step-12-complete']
completedAt: 2026-02-03
inputDocuments: ["README.md"]
workflowType: 'prd'
documentCounts:
  briefCount: 0
  researchCount: 0
  brainstormingCount: 0
  projectDocsCount: 1
referenceLinks:
  - "http://117.175.143.55:17860/ - SWIFT WebUI 参考界面"
  - "https://swift.readthedocs.io/zh-cn/latest/ - SWIFT 官方文档"
classification:
  projectType: web_app
  domain: ai_ml_tools
  complexity: high
  projectContext: brownfield
targetUsers:
  - "AI 研究员"
concurrentTasks: 8
integrationWithInstanceModule: true
storageStrategy: "容器内存储"
---

# Product Requirements Document - LoRAForge

**Author:** hequan
**Date:** 2026-02-03

---

## 执行摘要

### 产品概述

LoRAForge 模型微调模块是 LoRAForge 云资源管理平台的扩展功能，为 AI 研究员提供一站式的模型微调训练能力。通过 GUI 界面复刻 SWIFT WebUI 的全部功能，用户无需手动管理 Docker 容器即可完成模型训练任务。

### 目标用户

- **主要用户：** AI 研究员（偏好 GUI 界面，专注于模型效果而非基础设施）
- **次要用户：** 运维工程师（负责算力节点和资源管理）

### 核心价值

- **一站式体验：** 云资源管理 + 模型微调训练统一平台
- **零容器管理：** 自动创建、监控、清理训练容器
- **实时可视化：** 训练进度、损失曲线、GPU 利用率实时监控
- **深度集成：** 与现有实例管理模块无缝集成

### 技术架构

- **前端：** Vue 3 + Element Plus SPA，WebSocket 实时通信
- **后端：** Go + Gin，通过 API 调用 SWIFT WebUI 服务
- **容器：** Docker 容器隔离，GPU 资源动态分配
- **存储：** 容器内存储，7 天自动清理

### 范围与里程碑

| 阶段 | 目标 | 交付内容 |
|------|------|----------|
| **MVP** | 验证核心流程可行性 | LLM 预训练/微调、实时监控、结果下载、实例集成 |
| **Growth** | 扩展功能和用户群 | LLM 推理、导出、评测、训练模板、8 并发全开 |
| **Vision** | 一站式 MLOps 平台 | 完整 7 大模块、分布式训练、AutoML、MLOps 集成 |

### 关键指标

- **并发能力：** 系统 8 个并发任务，单用户 1 个任务
- **启动时间：** < 5 分钟从提交到训练开始
- **状态同步：** < 2 秒延迟实时推送训练状态
- **数据保留：** 容器保留 7 天，超期自动清理

### 功能需求总数

- **功能需求（FR）：** 56 个
- **非功能需求（NFR）：** 26 个
- **能力领域：** 8 个

---

## 成功标准

### 用户成功

**核心用户价值：** AI 研究员能够通过 LoRAForge 平台快速启动模型微调任务，无需手动管理 Docker 容器和底层基础设施。

| 成功指标 | 具体定义 | 测量方式 |
|----------|----------|----------|
| **任务启动速度** | 从提交参数到训练开始 < 5 分钟 | 计算从点击"开始训练"到容器就绪的时间 |
| **实时监控可见性** | 用户可随时查看训练进度、损失曲线、GPU 利用率 | WebSocket 实时推送训练状态 |
| **结果可追溯** | 每次训练任务的参数、输出、日志完整记录 | 任务详情页展示完整元数据 |
| **零容器管理负担** | 用户无需手动执行任何 Docker 命令 | 系统自动创建、管理、清理容器 |
| **并发任务支持** | 同时运行最多 8 个训练任务互不干扰 | 资源调度器确保任务隔离 |

**用户情绪成功时刻：**
- ✅ 看到训练损失曲线平稳下降时的安心
- ✅ 评估指标达到预期时的兴奋
- ✅ 一键下载/部署微调后模型的便利

### 业务成功

**平台价值：** LoRAForge 成为 AI 研究员进行模型微调的首选云平台。

| 时间线 | 目标 | 成功指标 |
|--------|------|----------|
| **3 个月** | MVP 功能可用，核心用户验证 | - 10+ 活跃用户<br>- 100+ 成功训练任务<br>- 训练任务成功率 > 95% |
| **6 个月** | 功能完善，用户增长 | - 50+ 活跃用户<br>- 500+ 成功训练任务<br>- 月留存率 > 60% |
| **12 个月** | 生态建立，品牌认知 | - 成为团队内部标准工具<br>- 与 CI/CD 流程集成<br>- 训练模板库建立 |

**差异化价值：**
- 🎯 **一站式管理**：云资源 + 训练任务统一平台
- 🎯 **智能调度**：自动分配最优算力节点
- 🎯 **团队协作**：任务共享、模板复用
- 🎯 **成本透明**：按训练时长计费，资源使用可视化

### 技术成功

**系统可靠性：** 8 个并发训练任务同时运行时系统稳定运行。

| 技术指标 | 目标值 | 验证方式 |
|----------|--------|----------|
| **API 可用性** | 99.5% | 监控 SWIFT WebUI API 响应成功率 |
| **训练启动时间** | < 5 分钟 | 从提交请求到容器就绪的时间 |
| **状态同步延迟** | < 2 秒 | 训练状态到前端显示的延迟 |
| **容器自愈** | 100% | 异常容器自动重启/迁移 |
| **资源隔离** | 0 冲突 | 多任务 GPU/CPU/内存隔离验证 |

**集成要求：**
- ✅ 与「实例管理」模块深度集成
- ✅ 训练任务作为特殊实例类型管理
- ✅ 统一的权限控制和审计日志
- ✅ 复用现有 WebSSH 能力（可选）

### 可衡量成果

**MVP 发布标准（必须满足）：**
1. ✅ 支持 LLM 预训练/微调完整流程
2. ✅ 与实例管理模块集成
3. ✅ 实时训练状态监控
4. ✅ 支持 3 个并发训练任务
5. ✅ 训练输出可下载

**Growth 阶段标准：**
1. ✅ 支持 8 个并发训练任务
2. ✅ 新增 LLM 推理、导出、评测功能
3. ✅ 训练模板系统
4. ✅ 任务队列和优先级调度

**Vision 阶段标准：**
1. ✅ 完整 7 大模块全部实现
2. ✅ 支持分布式训练
3. ✅ 自动超参数优化
4. ✅ 与主流 MLOps 平台集成

---

## 产品范围

### MVP - 最小可行产品

**核心目标：** 验证"云资源管理 + 模型微调"集成的可行性。

| 功能模块 | 描述 |
|----------|------|
| **LLM 预训练/微调** | 完整复刻 SWIFT WebUI 的核心训练功能 |
| **参数配置界面** | 模型设置、数据集设置、训练参数设置 |
| **任务管理** | 创建、启动、停止、删除训练任务 |
| **实时监控** | 训练进度、损失曲线、GPU 利用率实时显示 |
| **与实例管理集成** | 训练任务作为特殊实例类型管理 |
| **结果下载** | 训练输出（模型权重、日志）可下载 |

**不在 MVP 范围：**
- ❌ 人类对齐（DPO、PPO 等）
- ❌ GRPO 训练
- ❌ 自动超参数优化
- ❌ 分布式训练

### Growth 功能（MVP 后）

**目标：** 提升竞争力，扩大用户群。

| 功能模块 | 描述 |
|----------|------|
| **LLM 推理** | 微调后模型的在线推理服务 |
| **LLM 导出** | 模型合并、量化、推送到 ModelScope |
| **LLM 评测** | 标准数据集自动评估 |
| **训练模板** | 预设常用模型和数据集组合 |
| **任务队列** | 高级排队和优先级调度 |
| **8 并发支持** | 从 3 个并发扩展到 8 个 |

### Vision（未来愿景）

**目标：** 成为一站式 MLOps 平台。

| 功能模块 | 描述 |
|----------|------|
| **人类对齐** | DPO、PPO、KTO、ORPO、SimPO 等完整支持 |
| **GRPO 训练** | Group Relative Policy Optimization |
| **LLM 采样** | 大模型蒸馏采样 |
| **分布式训练** | 多节点、多 GPU 联合训练 |
| **AutoML** | 自动超参数搜索和架构优化 |
| **MLOps 集成** | 与 MLflow、Weights & Biases 等平台集成 |

---

## 用户旅程

### 旅程 1: AI 研究员 - 首次微调任务（核心成功路径）

**主角：** 小明，NLP 方向的 AI 研究员

> **人物画像**
> - **背景：** 专注于问答系统研究，熟悉深度学习概念但不擅长命令行操作
> - **偏好：** 喜欢 GUI 界面，希望直观地看到训练进度和结果
> - **目标：** 微调 Qwen2.5-7B 模型提升特定领域问答效果
> - **工作方式：** 一次专注一个实验，对比模型效果后再进行下一个

#### 🎬 开场场景：痛点时刻

周三下午，小明盯着 SSH 终端发呆。他尝试了第三次 Docker 命令，但容器还是因为 GPU 内存不足崩溃了。

**他的现状：**
- ❌ 需要记住复杂的 Docker 命令
- ❌ 无法直观看到训练进度，只能盯着日志文件
- ❌ 多个实验难以管理，容易搞混参数配置
- ❌ 想要对比不同参数效果时，手动记录非常麻烦

**内心独白：** *"我只是想微调一个模型，为什么要花这么多时间在环境配置和容器管理上？"*

#### 📈 上升动作：发现 LoRAForge

同事告诉他团队内部有个新平台 LoRAForge，可以直接在网页上配置和启动训练。

**第一次使用体验：**

1. **登录平台** → 看到清晰的「模型微调」模块入口
2. **选择模型** → 从下拉列表选择 Qwen2.5-7B-Instruct（自动匹配模板类型）
3. **配置数据集** → 上传自己的 JSONL 数据集文件
4. **设置训练参数** → GUI 界面调整学习率、批次大小、训练轮数
5. **选择算力** → 系统自动推荐有可用 GPU 的节点
6. **点击「开始训练」** → ✅ 任务提交成功！

**情绪变化：** 疑惑 → 好奇 → 小心翼翼 → 轻松

#### 🎯 高潮时刻：训练进行中

五分钟后，小明的浏览器收到通知：**"您的训练任务已开始运行"**

他打开任务详情页面，看到：
- 📊 **实时损失曲线**：平滑下降，训练正常
- 🖥️ **GPU 利用率**：92%，资源充分利用
- 📈 **训练进度**：15% | 预计剩余时间：2小时45分
- 📝 **实时日志**：训练输出滚动显示

**内心独白：** *"这就是我想要的！不需要 SSH，不需要命令行，一切都在这个页面里！"*

#### 🌅 结局：成果展示

三小时后，训练完成。小明：

1. **查看评估结果** → 准确率从 72% 提升到 89%
2. **下载模型权重** → 一键下载微调后的 LoRA 权重
3. **保存为模板** → 将这次成功的参数配置保存为模板，方便下次复用
4. **查看费用** → 本次训练花费 12.5 元，明细清晰

**新现实：**
- ✅ 从想法到训练完成，全程不超过 4 小时
- ✅ 所有实验记录在平台，随时查看历史
- ✅ 可以专注于模型效果，而不是基础设施

---

### 旅程 2: AI 研究员 - 任务失败与恢复

**主角：** 小明，已经成功完成一次训练的自信用户

#### 🎬 开场场景：信心满满

第一次训练成功后，小明想要试试更大的学习率，看看能不能进一步提升效果。他复制之前的任务模板，修改了学习率参数，点击「开始训练」。

#### ⚠️ 冲突：训练失败

十分钟后，他收到通知：**"您的训练任务已失败"**

打开任务详情，看到：
- 🔴 **状态：** 失败
- 💬 **错误信息：** `CUDA out of memory. Tried to allocate 2.5GB`
- 📊 **失败时间：** 训练进行到 35% 时

**第一反应：** *"什么？又OOM了？怎么办..."*

#### 🛠️ 上升动作：系统辅助诊断

LoRAForge 平台不是只给他一个错误信息，而是提供了：

1. **智能建议：** *"检测到 GPU 内存不足，建议：减小批次大小 或 启用梯度累积"*
2. **一键修改：** 直接在失败任务上点击「基于此任务创建新任务」
3. **参数推荐：** 系统建议将 `batch_size` 从 16 改为 8

**情绪变化：** 沮丧 → 疑惑 → 明白 → 重新燃起希望

#### 🎯 高潮时刻：成功恢复

小明按照建议修改参数，重新提交任务。

这次训练顺利完成！最终评估结果：
- 准确率：91%（比之前还高！）
- 原来：较小的批次大小虽然慢一点，但收敛更稳定

#### 🌅 结局：学会了调试

小明现在不仅会用平台，还学会了调参技巧：
- ✅ 失败不是终点，平台会帮助诊断
- ✅ 每次失败都是学习机会
- ✅ 实验记录完整，可以对比不同参数的效果

---

### 旅程 3: 运维工程师 - 平台监控与资源管理

**主角：** 老张，负责 LoRAForge 平台运维的工程师

> **人物画像**
> - **背景：** 5 年运维经验，熟悉 Docker 和 GPU 调度
> - **职责：** 确保平台稳定运行，资源高效利用
> - **关注：** 节点健康状态、资源利用率、异常处理

#### 🎬 开场场景：例行巡检

周一早上，老张打开 LoRAForge 的运维监控大屏：

**当前状态概览：**
- 🖥️ **在线算力节点：** 5/5 正常
- 🔥 **运行中任务：** 4 个
- 📊 **GPU 利用率：** 平均 78%
- 💰 **今日计费：** 326.8 元

一切看起来正常。

#### ⚠️ 冲突：节点告警

下午 2 点，老张收到告警：**"节点 #3 GPU 温度过高"**

他打开节点详情页：
- 🔴 **GPU 温度：** 88°C（阈值 85°C）
- 🔄 **运行中任务：** 2 个
- 📊 **内存使用：** 45GB/48GB

**第一反应：** *"需要马上处理，否则任务会受影响"*

#### 🛠️ 上升动作：运维操作

老张有几个选择：

1. **查看任务详情** → 确认是哪个任务占用了大量资源
2. **任务迁移** → 将任务迁移到其他空闲节点
3. **节点下线** → 如果问题严重，暂时下线节点进行维护

他选择先迁移任务：
- 在任务列表中选择任务 #2047
- 点击「迁移到其他节点」
- 系统自动选择最优节点：#1（GPU 温度 62°C）
- ✅ 迁移成功，任务继续运行

#### 🎯 高潮时刻：问题解决

任务迁移后，节点 #3 的负载下降：
- 🌡️ **GPU 温度：** 降至 65°C
- 📊 **内存使用：** 降至 12GB/48GB

老张决定将节点 #3 下线进行维护：
- 点击「下线节点」
- 系统自动将新任务调度到其他节点
- ✅ 平台整体服务不中断

#### 🌅 结局：运维无忧

老张的日常工作变得轻松：
- ✅ 统一监控界面，不再需要逐个 SSH 到节点
- ✅ 自动告警，问题早发现
- ✅ 任务迁移一键完成，不影响用户
- ✅ 资源使用可视化，便于规划扩容

---

### 旅程需求总结

基于以上三个用户旅程，我们识别出以下关键功能需求：

| 旅程 | 核心需求 | 对应功能 |
|------|----------|----------|
| **旅程 1：首次训练** | 友好的 GUI 配置界面 | 表单化参数输入、下拉选择、智能默认值 |
| | 实时进度可见 | WebSocket 实时推送、损失曲线图表 |
| | 一键启动/下载 | 任务操作按钮、结果下载 |
| | 参数模板保存 | 训练模板系统 |
| **旅程 2：失败恢复** | 清晰的错误信息 | 错误解析与展示 |
| | 智能修复建议 | 常见问题诊断与建议 |
| | 快速重新提交 | "基于此任务创建新任务"功能 |
| | 实验对比 | 历史任务对比功能 |
| **旅程 3：运维监控** | 全局状态监控 | 运维大屏、节点健康度 |
| | 任务管理 | 任务列表、批量操作 |
| | 任务迁移 | 在线任务迁移功能 |
| | 告警通知 | 异常事件通知 |
| | 资源统计 | GPU/内存/存储使用统计 |

---

## 领域特定需求

### 概述

本产品属于 **AI/ML 开发工具** 领域，复杂度为 **高**。该领域有以下独特挑战：

- **资源密集型**：GPU 资源昂贵且有限，训练任务运行时间长
- **技术复杂度高**：涉及容器编排、GPU 调度、分布式训练
- **用户专业性强**：目标用户是 AI 研究员，对工具有较高要求
- **实验迭代频繁**：需要支持快速实验、参数对比、结果分析

---

### 技术约束

#### GPU 资源管理

| 约束 | 描述 | 解决方案 |
|------|------|----------|
| **资源有限** | GPU 数量有限，成本高昂 | 8 并发限制，任务队列管理 |
| **需求不可预测** | 不同模型和批次大小的内存需求差异大 | 智能资源推荐，OOM 自动恢复 |
| **长时间运行** | 训练任务可能持续数小时到数天 | Checkpoint 定期保存，支持断点续训 |
| **资源隔离** | 多租户环境下的任务互不干扰 | Docker 容器隔离，GPU 显式分配 |

#### 性能要求

| 指标 | 要求 | 说明 |
|------|------|------|
| **训练启动时间** | < 5 分钟 | 从提交到容器就绪开始训练 |
| **状态同步延迟** | < 2 秒 | 训练状态实时推送到前端 |
| **Checkpoint 间隔** | 可配置 | 默认每 10 分钟保存一次 |
| **日志实时性** | < 1 秒延迟 | 训练输出实时显示 |

---

### 数据与隐私

#### 数据安全

| 关注点 | 要求 | MVP 策略 |
|--------|------|----------|
| **训练数据隐私** | 用户数据可能包含敏感信息 | 容器内存储，任务结束后清理 |
| **模型权重访问** | 微调后的模型谁有权访问 | 仅创建者可下载，管理员可查看 |
| **数据传输** | 模型权重下载可能很大 | 支持断点续传，HTTPS 加密 |
| **数据留存** | 任务结束后数据保留多久 | 容器默认保留 7 天，超期自动清理 |

#### MVP 阶段策略

- ✅ 训练数据和输出暂时存储在容器内
- ✅ 任务结束后容器保留 7 天
- ✅ 用户可主动下载模型权重和日志
- ❌ 暂不支持永久存储或对象存储集成

---

### 可观测性与调试

#### 训练过程监控

AI 研究员需要详细的训练过程信息：

| 监控项 | 描述 | 实现方式 |
|--------|------|----------|
| **损失曲线** | 实时显示训练/验证损失 | WebSocket 推送 + ECharts 可视化 |
| **训练进度** | 当前 step/总 step，已用时间/预计剩余 | 实时计算并推送 |
| **GPU 利用率** | GPU 使用率、显存占用、温度 | Docker API 获取 + 定期轮询 |
| **训练日志** | 完整的训练输出 | Docker Exec API 实时流式传输 |

#### Checkpoint 管理

| 功能 | 描述 | MVP 范围 |
|------|------|----------|
| **自动保存** | 定期保存训练 checkpoint | ✅ 默认每 10 分钟 |
| **手动保存** | 用户主动触发 checkpoint 保存 | ❓ 后续版本 |
| **从 Checkpoint 恢复** | 支持从 checkpoint 继续训练 | ✅ 必需 |
| **Checkpoint 下载** | 用户可下载 checkpoint 文件 | ✅ 必需 |

---

### 集成需求

#### 与 ModelScope Hub 集成

| 功能 | 描述 | MVP 范围 |
|------|------|----------|
| **模型下载** | 从 ModelScope Hub 下载预训练模型 | ✅ 通过 SWIFT 自动处理 |
| **数据集下载** | 从 ModelScope Hub 下载训练数据集 | ✅ 通过 SWIFT 自动处理 |
| **模型上传** | 将微调后的模型推送到 Hub | ❌ Growth 阶段 |
| **模型量化** | 量化模型以减少体积 | ❌ Growth 阶段 |

#### 与现有模块集成

| 模块 | 集成方式 | 描述 |
|------|----------|------|
| **实例管理** | 训练任务作为特殊实例类型 | 统一管理，复用现有能力 |
| **用户权限** | 基于 RBAC 的权限控制 | 与现有权限系统集成 |
| **审计日志** | 记录所有关键操作 | 与现有日志系统集成 |
| **计费系统** | 按训练时长计费 | 与现有计费逻辑集成 |

---

### 风险与缓解

| 风险 | 影响 | 概率 | 缓解措施 |
|------|------|------|----------|
| **GPU 资源耗尽** | 用户无法启动训练 | 中 | 任务队列、资源预留、排队等待提示 |
| **训练任务卡死** | 资源浪费、用户不满 | 中 | 超时机制、心跳检测、自动标记失败 |
| **数据丢失** | 用户工作成果丢失 | 低 | Checkpoint 定期保存、容器持久化 |
| **容器逃逸** | 安全风险 | 低 | 容器隔离、资源限制、非 root 运行 |
| **API 不兼容** | SWIFT API 变更导致功能失效 | 中 | 版本锁定、兼容性测试 |
| **网络中断** | 训练状态无法同步 | 中 | 本地缓存、断线重连 |

---

### 技术架构考虑

#### 容器生命周期

```
用户提交任务
    ↓
创建实例记录（状态：Pending）
    ↓
选择算力节点（智能调度）
    ↓
创建 Docker 容器（挂载数据卷）
    ↓
等待容器就绪（健康检查）
    ↓
执行训练命令
    ↓
状态：Running（实时监控）
    ↓
训练完成/失败
    ↓
状态：Completed/Failed
    ↓
容器保留 7 天（可下载结果）
    ↓
自动清理
```

#### SWIFT WebUI API 集成

| API 端点 | 用途 | 调用方式 |
|----------|------|----------|
| `/api/train/start` | 启动训练任务 | 后端 → SWIFT API |
| `/api/train/status` | 查询训练状态 | 定期轮询 + WebSocket |
| `/api/train/stop` | 停止训练任务 | 用户触发 |
| `/api/train/logs` | 获取训练日志 | 实时流式传输 |
| `/api/train/download` | 下载训练输出 | 代理下载 |

---

### 领域最佳实践

基于 AI/ML 训练平台的设计经验：

1. **资源优先级**：训练任务按提交时间排队，VIP 用户优先（未来）
2. **失败快速反馈**：尽早检测资源不足等问题，避免浪费时间
3. **实验可复现**：完整记录每次训练的参数配置，支持一键复现
4. **成本透明化**：实时显示资源消耗和费用，避免意外超支
5. **渐进式披露**：GUI 界面默认显示常用参数，高级参数可展开

---

## Web 应用特定需求

### 项目类型概述

LoRAForge 模型微调模块是一个基于 Vue 3 的 **SPA（单页应用）**，作为现有 gin-vue-admin 框架的扩展模块开发。采用前后端分离架构，遵循现有的分层设计模式。

### 技术栈选型

| 层级 | 技术选型 | 版本 | 用途 |
|------|----------|------|------|
| **前端框架** | Vue | 3.5+ | 渐进式前端框架 |
| **构建工具** | Vite | 6.2+ | 快速开发构建 |
| **UI 组件库** | Element Plus | 2.10+ | 企业级 UI 组件 |
| **状态管理** | Pinia | 2.2+ | 全局状态管理 |
| **路由** | Vue Router | 4.4+ | 单页应用路由 |
| **HTTP 客户端** | Axios | 1.8+ | API 请求封装 |
| **实时通信** | WebSocket | - | 训练状态推送 |
| **图表库** | ECharts | 5.5+ | 损失曲线可视化 |
| **终端组件** | xterm.js | - | WebSSH（可选复用） |
| **原子化 CSS** | UnoCSS | 66.4+ | 原子化 CSS 引擎 |
| **后端框架** | Gin | 1.10+ | Web 服务框架 |
| **ORM** | GORM | 1.25+ | 数据库操作 |
| **WebSocket** | Gorilla WebSocket | - | 实时通信 |

### 浏览器支持矩阵

| 浏览器 | 最低版本 | 支持级别 | 说明 |
|--------|----------|----------|------|
| Chrome | 90+ | ✅ 完全支持 | 主要目标浏览器 |
| Edge | 90+ | ✅ 完全支持 | Chromium 内核 |
| Firefox | 88+ | ✅ 完全支持 | 次要支持 |
| Safari | 14+ | ⚠️ 尽力支持 | 可能存在兼容性问题 |

**不支持：** IE11 及更低版本

### 实时功能架构

| 功能 | 优先级 | 技术方案 | 说明 |
|------|--------|----------|------|
| **训练状态推送** | P0 必需 | WebSocket | 后端主动推送状态变更 |
| **GPU 监控数据** | P0 必需 | 轮询 + 推送 | 定期轮询 + 变化推送 |
| **训练日志流** | P1 重要 | Server-Sent Events | 实时日志流式传输 |
| **系统通知** | P2 可选 | 浏览器通知 API | 桌面通知 |

#### WebSocket 连接管理

```
前端 WebSocket 连接流程:
1. 用户打开任务详情页 → 建立 WebSocket 连接
2. 后端订阅任务状态变更 → 推送状态更新
3. 前端接收更新 → 刷新 UI（进度条、损失曲线）
4. 任务完成/失败 → 后端发送最终状态 → 前端关闭连接
```

### 性能目标

| 指标 | 目标值 | 验证方式 |
|------|--------|----------|
| **首屏加载时间** | < 3 秒 | Lighthouse 测试 |
| **路由切换** | < 500 ms | Performance API |
| **API 平均响应** | < 500 ms | 后端日志监控 |
| **状态同步延迟** | < 2 秒 | 端到端测试 |
| **大文件上传** | 支持 > 5GB | 分片上传 + 断点续传 |

### 响应式设计策略

| 设备类型 | 支持策略 | 布局方式 |
|----------|----------|----------|
| **桌面（>1440px）** | ✅ 主要支持 | 多列布局，完整功能 |
| **笔记本（1024-1440px）** | ✅ 完全支持 | 双列布局 |
| **平板（768-1024px）** | ⚠️ 可选支持 | 单列布局，简化功能 |
| **手机（<768px）** | ❌ 不推荐 | 训练参数配置过于复杂 |

**注意：** 训练参数配置界面涉及大量表单项，不适合小屏幕操作。

### 前端模块结构

```
web/src/view/fine_tune/
├── index.vue                  # 模块主入口
├── components/                # 业务组件
│   ├── ModelSelector.vue      # 模型选择器
│   ├── DatasetUploader.vue    # 数据集上传
│   ├── TrainConfig.vue        # 训练参数配置
│   ├── MonitorPanel.vue       # 实时监控面板
│   ├── LossChart.vue          # 损失曲线图表
│   ├── GPUStats.vue           # GPU 统计卡片
│   └── TaskList.vue           # 任务列表
├── api/
│   └── fine_tune.js           # API 封装
└── pinia/modules/
    └── fine_tune.js           # 模块状态管理
```

### 后端模块结构

```
server/
├── api/v1/fine_tune/
│   ├── enter.go               # API 组入口
│   └── fine_tune_api.go       # API 控制器
├── service/fine_tune/
│   ├── enter.go               # 服务组入口
│   ├── fine_tune_service.go   # 业务逻辑
│   └── swift_client.go        # SWIFT API 客户端
├── model/fine_tune/
│   ├── fine_tune_task.go      # 训练任务模型
│   └── request/
│       └── fine_tune.go       # 请求/响应模型
└── router/fine_tune/
    ├── enter.go               # 路由组入口
    └── fine_tune_router.go    # 路由定义
```

### 实现考虑

#### 前端关键点

1. **组件复用**：最大化复用 Element Plus 组件，保持 UI 一致性
2. **状态持久化**：使用 Pinia 持久化插件保存用户配置
3. **错误处理**：统一的错误拦截和用户友好提示
4. **加载状态**：异步操作提供 loading 反馈
5. **表单验证**：客户端预验证 + 服务端验证

#### 后端关键点

1. **SWIFT API 封装**：统一的 HTTP 客户端处理 SWIFT API 调用
2. **异步任务处理**：训练任务异步执行，不阻塞 API 响应
3. **状态同步**：定时轮询 + WebSocket 推送双重机制
4. **容器生命周期**：完整的容器创建、监控、清理流程
5. **错误恢复**：异常状态的自动检测和恢复

#### WebSocket 消息格式

```json
{
  "type": "train_status",
  "taskId": "12345",
  "data": {
    "status": "running",
    "progress": 45,
    "loss": 0.234,
    "gpuUtilization": 92,
    "eta": "2h15m"
  }
}
```

---

## 项目范围与分阶段开发

### MVP 策略

**MVP 类型：** 问题解决型 MVP

**核心目标：** 验证"云资源管理 + 模型微调"一体化集成的可行性，让 AI 研究员能够通过友好的 GUI 界面快速启动训练任务并获得结果。

**资源需求：**
- 前端开发：1 人（Vue 3 + Element Plus）
- 后端开发：1 人（Go + Gin + Docker API）
- 测试：复用现有测试资源
- 预计工作量：4-6 周

### MVP 功能集（Phase 1）

#### 支持的核心用户旅程

| 旅程 | 支持程度 | 说明 |
|------|----------|------|
| **首次训练** | ✅ 完整支持 | 从配置到结果下载完整流程 |
| **失败恢复** | ⚠️ 基础支持 | 显示错误、支持重新提交 |
| **运维监控** | ⚠️ 基础支持 | 任务列表、状态查看 |

#### 必备功能清单

**模型配置（P0）：**
- 模型 ID/路径选择（下拉 + 手动输入）
- 模型类型自动匹配
- Prompt 模板类型选择
- System 字段配置
- 训练记录加载

**数据集配置（P0）：**
- 数据集名称/路径配置
- 本地文件上传（JSONL 格式）
- 验证集拆分比例
- 句子最大长度设置

**训练参数（P0）：**
- 训练 Stage 选择（预训练/微调）
- 训练方式（LoRA/全量）
- 随机数种子
- 训练精度（bf16/fp16/fp32）
- GPU 选择（单选/多选）
- DDP 设置（可选）

**任务管理（P0）：**
- 创建训练任务
- 启动/停止任务
- 删除任务
- 任务列表展示
- 任务详情查看

**实时监控（P0）：**
- 训练进度（当前 step/总 step）
- 损失曲线（实时图表）
- GPU 利用率（实时数据）
- 训练日志（实时流式）

**结果管理（P0）：**
- 模型权重下载
- 训练日志下载
- Checkpoint 下载

**实例集成（P1）：**
- 训练任务作为特殊实例类型
- 在实例列表中显示
- 统一的生命周期管理

### MVP 外功能

| 功能 | MVP 状态 | 计划阶段 |
|------|----------|----------|
| 训练模板保存/加载 | ❌ | Phase 2 |
| 任务队列和优先级 | ❌ | Phase 2 |
| 智能错误诊断 | ❌ | Phase 2 |
| 运维监控大屏 | ❌ | Phase 2 |
| 任务迁移 | ❌ | Phase 2 |
| 高级参数调优 | ⚠️ 默认值 | Phase 2 |

### Post-MVP 功能

#### Phase 2：Growth（增长阶段）

**目标：** 提升竞争力，扩大用户群，完善用户体验。

| 功能模块 | 描述 | 优先级 |
|----------|------|--------|
| **LLM 推理** | 微调后模型在线推理服务 | P0 |
| **LLM 导出** | 模型合并、量化、推送到 ModelScope | P0 |
| **LLM 评测** | 标准数据集自动评估 | P1 |
| **训练模板** | 预设常用配置，一键应用 | P1 |
| **任务队列** | 智能排队、优先级调度 | P1 |
| **8 并发全开** | 从 MVP 3 并发扩展到 8 并发 | P1 |
| **智能错误诊断** | 常见问题自动分析和建议 | P2 |
| **运维大屏** | 专门的运维监控仪表板 | P2 |

#### Phase 3：Expansion（扩展阶段）

**目标：** 完整 7 大模块，成为一站式 MLOps 平台。

| 功能模块 | 描述 |
|----------|------|
| **LLM 人类对齐** | DPO、PPO、KTO、ORPO、SimPO 等完整支持 |
| **LLM GRPO** | Group Relative Policy Optimization |
| **LLM 采样** | 大模型蒸馏采样 |
| **分布式训练** | 多节点、多 GPU 联合训练 |
| **AutoML** | 自动超参数搜索和架构优化 |
| **MLOps 集成** | 与 MLflow、Weights & Biases 等平台集成 |

### 风险缓解策略

#### 技术风险

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| **SWIFT API 不兼容** | 核心功能失效 | - Docker 镜像版本锁定<br>- API 兼容性测试<br>- 预留升级适配时间 |
| **WebSocket 连接不稳定** | 状态同步失败 | - 双重机制（轮询 + 推送）<br>- 自动重连机制<br>- 本地状态缓存 |
| **容器资源泄漏** | 资源耗尽 | - 容器生命周期严格管理<br>- 超时自动清理<br>- 资源使用监控 |
| **长时间任务中断** | 用户工作丢失 | - Checkpoint 定期保存<br>- 支持断点续训<br>- 任务状态持久化 |

#### 市场风险

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| **用户采用率低** | 平台价值无法体现 | - 早期用户内测<br>- 快速反馈迭代<br>- 用户体验优化 |
| **竞争产品降价** | 价格优势丧失 | - 差异化定位（一体化）<br>- 提升用户体验<br>- 增值服务（模板、评测） |

#### 资源风险

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| **开发时间超期** | MVP 延迟交付 | - 功能分层，可随时截断<br>- 复用现有组件<br>- 优先核心功能 |
| **GPU 资源不足** | 用户无法启动任务 | - 任务队列机制<br>- 资源预留策略<br>- 弹性扩容方案 |
| **人力不足** | 开发进度缓慢 | - 明确优先级<br>- 外包非核心功能<br>- 技术债务管理 |

### 范围决策记录

**已做出的关键范围决策：**

1. **MVP 聚焦核心训练流程** - 优先支持 LLM 预训练/微调，其他 6 个模块后续添加
2. **单用户单任务** - 系统支持 8 并发，但单用户一次只能运行 1 个任务
3. **容器内存储** - 数据和结果暂存容器，7 天后自动清理
4. **深度集成实例管理** - 训练任务作为特殊实例类型，统一管理
5. **GUI 优先** - 针对偏好 GUI 的 AI 研究员，暂不提供 CLI

---

## 功能需求

### 概述

本节定义了 LoRAForge 模型微调模块的完整能力清单。这些功能需求是**能力契约**，所有下游工作（UX 设计、架构设计、Epic 拆分）都必须基于此清单。

**功能需求总数：** 56 个
**能力领域：** 8 个

---

### 1. 训练配置

**FR1:** AI 研究员可以从预定义列表中选择预训练模型

**FR2:** AI 研究员可以手动输入模型路径或 URL

**FR3:** 系统根据选择的模型自动匹配模型类型

**FR4:** AI 研究员可以选择或编辑 Prompt 模板类型

**FR5:** AI 研究员可以配置 System 字段内容

**FR6:** AI 研究员可以上传本地训练数据集文件

**FR7:** AI 研究员可以指定远程数据集路径

**FR8:** AI 研究员可以设置验证集拆分比例

**FR9:** AI 研究员可以配置句子最大长度

**FR10:** AI 研究员可以选择训练 Stage（预训练/微调）

**FR11:** AI 研究员可以选择训练方式（LoRA/全量微调）

**FR12:** AI 研究员可以设置随机数种子

**FR13:** AI 研究员可以选择训练精度（bf16/fp16/fp32）

**FR14:** AI 研究员可以选择使用的 GPU 设备

**FR15:** AI 研究员可以启用或禁用 DDP 数据并行

**FR16:** AI 研究员可以查看历史训练记录并重新加载配置

---

### 2. 任务管理

**FR17:** AI 研究员可以创建新的训练任务

**FR18:** AI 研究员可以查看所有训练任务的列表

**FR19:** AI 研究员可以查看单个任务的详细信息

**FR20:** AI 研究员可以启动已创建的训练任务

**FR21:** AI 研究员可以停止正在运行的训练任务

**FR22:** AI 研究员可以删除已完成的训练任务

**FR23:** AI 研究员可以基于历史任务创建新任务（复制配置）

**FR24:** 系统可以自动分配算力节点给训练任务

**FR25:** 系统可以检测任务状态变化并更新显示

---

### 3. 实时监控

**FR26:** AI 研究员可以查看训练任务的实时进度

**FR27:** AI 研究员可以查看训练损失的实时曲线图

**FR28:** AI 研究员可以查看 GPU 利用率的实时数据

**FR29:** AI 研究员可以查看 GPU 显存使用情况

**FR30:** AI 研究员可以查看训练日志的实时输出

**FR31:** AI 研究员可以查看预计剩余训练时间

**FR32:** 系统可以自动推送训练状态更新到前端

---

### 4. 结果管理

**FR33:** AI 研究员可以下载训练完成的模型权重文件

**FR34:** AI 研究员可以下载训练日志文件

**FR35:** AI 研究员可以下载训练 checkpoint 文件

**FR36:** AI 研究员可以查看训练完成后的评估结果

**FR37:** 系统可以保留训练输出一定时间（默认 7 天）

---

### 5. 实例集成

**FR38:** 训练任务可以作为特殊实例类型在实例管理中显示

**FR39:** AI 研究员可以通过实例管理页面查看训练任务状态

**FR40:** 运维人员可以统一管理所有实例（包括训练任务）

**FR41:** 系统可以复用实例管理模块的生命周期管理能力

---

### 6. 运维管理

**FR42:** 运维人员可以查看所有算力节点的健康状态

**FR43:** 运维人员可以查看每个节点的 GPU 使用情况

**FR44:** 运维人员可以查看每个节点的 GPU 温度

**FR45:** 运维人员可以将训练任务从一个节点迁移到另一个节点

**FR46:** 运维人员可以下线有问题的算力节点

**FR47:** 系统可以在检测到节点异常时发送告警通知

**FR48:** 系统可以自动清理超过保留期限的容器

---

### 7. 系统通知

**FR49:** AI 研究员可以接收训练任务开始的通知

**FR50:** AI 研究员可以接收训练任务完成的通知

**FR51:** AI 研究员可以接收训练任务失败的通知

**FR52:** 运维人员可以接收系统异常的告警通知

---

### 8. 用户权限

**FR53:** 系统可以根据用户角色限制功能访问

**FR54:** AI 研究员只能查看和操作自己创建的训练任务

**FR55:** 运维人员可以查看和管理所有训练任务

**FR56:** 系统可以记录所有关键操作的审计日志

---

### 功能优先级划分

| 优先级 | 功能需求 | 描述 |
|--------|----------|------|
| **P0 - MVP 必需** | FR1-FR40 | 核心训练流程、实时监控、结果管理、实例集成 |
| **P1 - Growth** | FR41-FR48 | 运维管理增强、系统通知 |
| **P2 - Expansion** | FR49-FR56 | 用户权限细化、高级运维功能 |

---

## 非功能需求

### 概述

非功能需求（NFR）规定系统**必须表现得多好**，而不是**必须做什么**。以下 NFR 仅包含与本项目相关的质量属性，不适用或无关的类别已省略。

---

### 性能

| NFR | 指标 | 验证方式 |
|-----|------|----------|
| **NFR-P1** | 训练任务从提交到开始运行的延迟 < 5 分钟 | 端到端测试 |
| **NFR-P2** | 训练状态同步延迟 < 2 秒 | WebSocket 监控 |
| **NFR-P3** | 页面首屏加载时间 < 3 秒 | Lighthouse 测试 |
| **NFR-P4** | API 平均响应时间 < 500 ms | 后端日志监控 |
| **NFR-P5** | 支持 8 个并发训练任务同时运行 | 负载测试 |

---

### 安全性

| NFR | 指标 | 验证方式 |
|-----|------|----------|
| **NFR-S1** | 所有 API 请求必须通过 JWT 认证 | 安全测试 |
| **NFR-S2** | 用户只能访问自己创建的训练任务 | 权限测试 |
| **NFR-S3** | 训练容器之间相互隔离，无法访问彼此数据 | 容器安全测试 |
| **NFR-S4** | 容器以非 root 用户运行 | 安全扫描 |
| **NFR-S5** | 敏感操作记录审计日志 | 日志审查 |
| **NFR-S6** | 与 SWIFT WebUI 的通信使用 HTTPS/TLS | 网络监控 |

---

### 可扩展性

| NFR | 指标 | 说明 |
|-----|------|------|
| **NFR-SC1** | 系统支持至少 8 个并发训练任务 | MVP 目标 |
| **NFR-SC2** | 单用户可创建的任务数无硬编码限制 | 支持实验迭代 |
| **NFR-SC3** | 支持动态添加算力节点 | 水平扩展 |
| **NFR-SC4** | 数据存储支持扩容到对象存储（预留接口） | 未来扩展 |

---

### 可靠性

| NFR | 指标 | 说明 |
|-----|------|------|
| **NFR-R1** | SWIFT WebUI API 可用性 > 99% | 月度统计 |
| **NFR-R2** | 训练任务异常后自动标记为失败状态 | 故障检测 |
| **NFR-R3** | Checkpoint 每 10 分钟自动保存 | 数据保护 |
| **NFR-R4** | WebSocket 连接断开后自动重连 | 连接恢复 |
| **NFR-R5** | 容器异常退出后保留日志供诊断 | 故障排查 |
| **NFR-R6** | 系统支持任务迁移以应对节点故障 | 容灾能力 |

---

### 集成

| NFR | 指标 | 说明 |
|-----|------|------|
| **NFR-I1** | 训练任务作为特殊实例类型在实例管理中显示 | 架构一致性 |
| **NFR-I2** | 复用现有 RBAC 权限系统 | 权限统一 |
| **NFR-I3** | 复用现有审计日志系统 | 日志统一 |
| **NFR-I4** | 与 SWIFT WebUI API 版本兼容性锁定 | 稳定性保证 |
| **NFR-I5** | 支持与 ModelScope Hub 的模型/数据集下载 | 生态集成 |

---

### 可维护性

| NFR | 指标 | 说明 |
|-----|------|------|
| **NFR-M1** | SWIFT WebUI API 版本升级时预留适配时间 | 可升级性 |
| **NFR-M2** | 容器镜像版本可配置 | 环境灵活性 |
| **NFR-M3** | 训练参数配置支持导出/导入 | 调试便利性 |

---

### 数据保留

| NFR | 指标 | 说明 |
|-----|------|------|
| **NFR-D1** | 训练容器在任务完成后保留 7 天 | 默认策略 |
| **NFR-D2** | 超过保留期的容器自动清理 | 资源管理 |
| **NFR-D3** | 用户可主动下载保留数据 | 用户控制 |

---

### NFR 优先级

| 优先级 | NFR 范围 | 描述 |
|--------|----------|------|
| **P0 - MVP 必需** | NFR-P1 至 NFR-P5, NFR-S1 至 NFR-S3, NFR-SC1, NFR-R2 至 NFR-R4, NFR-I1 至 NFR-I3, NFR-D1 至 NFR-D3 | 核心性能、基础安全、基本可靠性、集成要求 |
| **P1 - Growth** | NFR-S4 至 NFR-S6, NFR-SC2 至 NFR-SC4, NFR-R5 至 NFR-R6, NFR-I4 至 NFR-I5, NFR-M1 至 NFR-M3 | 增强安全、扩展能力、高级可靠性 |
| **P2 - Expansion** | 预留给未来的 NFR | 根据实际运营情况补充 |

